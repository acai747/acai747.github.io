<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Drug Use Prediction (Classification) | Andrew Cai</title>
  <meta name="description" content="Binary classification project focused on imbalanced data, model comparison, and evaluation metrics." />

  <style>
    :root{
      --bg:#f7f7fb;
      --card:#ffffff;
      --ink:#1f2a44;
      --muted:#58627a;
      --brand:#2563eb;
      --ring: rgba(37,99,235,.25);
      --border:#e9e9f3;
      --shadow: 0 8px 24px rgba(31,42,68,.06);
    }
    *{ box-sizing:border-box; }
    body{
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
      background:var(--bg);
      color:var(--ink);
      margin:0;
      line-height:1.6;
    }
    .wrap{ max-width: 900px; margin:0 auto; padding:24px; }

    header{ padding: 18px 0 8px; }
    header a{
      color:var(--brand);
      text-decoration:none;
      font-weight:700;
    }
    header a:hover{ text-decoration:underline; }

    h1{
      margin: 10px 0 6px;
      font-size: 1.9rem;
      letter-spacing:-.2px;
    }
    h2{ margin-top: 26px; font-size: 1.25rem; }
    h3{ margin-top: 18px; font-size: 1.05rem; }
    p{ margin: 10px 0; }
    ul{ margin: 8px 0 8px 18px; }
    li{ margin: 6px 0; }

    .meta{ color:var(--muted); font-size:.95rem; }

    section{
      background:var(--card);
      border-radius:14px;
      box-shadow: var(--shadow);
      padding:20px;
      margin: 16px 0;
      border: 1px solid var(--border);
    }

    .hero img{
      width:100%;
      border-radius:12px;
      margin-top: 10px;
      background:#eaeaf3;
    }

    .pillrow{
      display:flex;
      flex-wrap:wrap;
      gap:8px;
      margin-top: 10px;
    }
    .pill{
      font-size: .88rem;
      background:#f3f6ff;
      border:1px solid #e1e6ff;
      padding:4px 10px;
      border-radius: 999px;
      white-space: nowrap;
    }

    .btn{
      display:inline-block;
      padding:8px 12px;
      border-radius:10px;
      border:1px solid #d6daf1;
      text-decoration:none;
      color:var(--brand);
      font-weight:700;
      background:#f8faff;
      margin-right: 8px;
      margin-top: 6px;
    }
    .btn:hover{ box-shadow:0 0 0 4px var(--ring); }

    .code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      background:#f3f6ff;
      border:1px solid #e1e6ff;
      padding:2px 6px;
      border-radius:6px;
      font-size: .95em;
    }

    .kpi{
      display:grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 12px;
      margin-top: 12px;
    }
    .kpi .box{
      border:1px solid var(--border);
      border-radius:12px;
      padding:12px;
      background:#fff;
    }
    .kpi .box strong{ display:block; margin-bottom: 4px; }
    .kpi .box span{ color:var(--muted); font-size: .95rem; }

    footer{
      text-align:center;
      color:var(--muted);
      padding:24px 0 6px;
      font-size: .9rem;
    }
  </style>
</head>

<body>
  <div class="wrap">

    <!-- Back navigation -->
    <header>
      <a href="../../index.html">← Back to Portfolio</a>
    </header>

    <!-- Title / Overview -->
    <section class="hero">
      <h1>Drug Use Prediction (Imbalanced Classification)</h1>
      <p class="meta">
        Binary Classification · Imbalanced Learning · Model Comparison · Precision/Recall · AUC
      </p>

      <!-- Optional hero image -->
      <img src="../img/drug-users-binary.png" alt="Classification results preview (ROC curve / confusion matrix)" />

      <div class="pillrow">
        <span class="pill">Python</span>
        <span class="pill">Pandas</span>
        <span class="pill">Scikit-learn</span>
        <span class="pill">SVM</span>
        <span class="pill">Naïve Bayes</span>
        <span class="pill">AUC</span>
        <span class="pill">Imbalanced Data</span>
      </div>

      <p>
        Built and evaluated multiple machine learning classifiers to predict drug use outcomes, with a focus on
        handling class imbalance and choosing the right evaluation metrics.
      </p>

      <p>
        A key outcome was reframing the task from multiclass to binary classification, which substantially improved
        model stability and performance.
      </p>

      <p>
        <a class="btn" href="https://github.com/YOUR_USERNAME/YOUR_DRUG_CLASSIFICATION_REPO" target="_blank" rel="noopener">GitHub Repo</a>
      </p>
    </section>

    <!-- Problem -->
    <section>
      <h2>Problem Statement</h2>
      <p>
        Predicting drug use from survey-style or categorical-heavy datasets can be difficult due to noisy signals,
        limited feature representation, and severe class imbalance. Traditional accuracy can be misleading when positive
        cases are rare.
      </p>
      <p>
        The goal of this project was to build a robust classification workflow and compare models under both imbalanced
        and balanced conditions using precision, recall, and AUC.
      </p>
    </section>

    <!-- Data -->
    <section>
      <h2>Data & Features</h2>
      <p>
        The dataset included structured attributes describing individuals and behavioral patterns. The target variable
        was formulated as a classification outcome representing drug use.
      </p>
      <ul>
        <li>Feature types: categorical-heavy + structured numeric fields</li>
        <li>Challenge: strong class imbalance in the target label</li>
        <li>Focus: model performance on minority class detection (recall/precision)</li>
      </ul>
    </section>

    <!-- Approach -->
    <section>
      <h2>Approach</h2>
      <p>
        We compared multiple classifiers and evaluated performance under both imbalanced and balanced settings.
        The project emphasized decision-making around problem framing and metric selection.
      </p>

      <ul>
        <li>Reframed the task from multiclass to <strong>binary classification</strong></li>
        <li>Evaluated models with metrics beyond accuracy (precision, recall, AUC)</li>
        <li>Compared balanced vs imbalanced training to quantify performance change</li>
        <li>Models explored included Linear SVM, Perceptron, and Complement Naïve Bayes</li>
      </ul>

      <p class="meta">
        (Implementation details can be summarized here — e.g., encoding strategy, scaling, cross-validation, or resampling method.)
      </p>
    </section>

    <!-- Results -->
    <section>
      <h2>Results</h2>

      <div class="kpi">
        <div class="box">
          <strong>Best Balanced Model (Linear SVM)</strong>
          <span>Precision: 70% · Recall: 70% · Accuracy: 70% · AUC: 76%</span>
        </div>
        <div class="box">
          <strong>Best Probabilistic Model (Complement NB)</strong>
          <span>Precision: 51% · Recall: 68% · Accuracy: 69% · AUC: 78%</span>
        </div>
        <div class="box">
          <strong>Balancing Impact</strong>
          <span>~15–20% improvement in recall and precision vs imbalanced training</span>
        </div>
      </div>

      <ul style="margin-top:12px;">
        <li>Binary classification significantly improved performance vs multinomial framing</li>
        <li>Linear SVM performed best overall on balanced training</li>
        <li>Complement Naïve Bayes produced strong AUC with competitive recall</li>
      </ul>
    </section>

    <!-- Model Insights -->
    <section>
      <h2>Model Insights</h2>
      <p>
        This project highlighted tradeoffs between margin-based and probabilistic classifiers on categorical-heavy datasets.
        It also emphasized why recall/precision and AUC are essential when the positive class is rare.
      </p>
      <ul>
        <li>Simpler models (e.g., Perceptron) struggled under imbalance and noisy categorical inputs</li>
        <li>Linear SVM benefited from balancing and produced stable decision boundaries</li>
        <li>Naïve Bayes offered strong AUC despite lower precision, suggesting different threshold tradeoffs</li>
      </ul>
    </section>

    <!-- Challenges -->
    <section>
      <h2>Challenges & Limitations</h2>
      <ul>
        <li>Class imbalance made naive accuracy misleading</li>
        <li>Categorical-heavy features required careful preprocessing and validation</li>
        <li>Model choice depended heavily on business goal (maximize recall vs precision)</li>
      </ul>
    </section>

    <!-- Extensions -->
    <section>
      <h2>Extensions & Future Work</h2>
      <ul>
        <li>Probability calibration and threshold tuning to optimize precision/recall tradeoffs</li>
        <li>More advanced imbalance handling (SMOTE, class-weighting strategies)</li>
        <li>Model interpretability (feature attribution / SHAP) to understand key drivers</li>
      </ul>
    </section>

    <!-- Takeaways -->
    <section>
      <h2>Key Takeaways</h2>
      <p>
        This project strengthened my experience in building end-to-end classification workflows, selecting the right metrics,
        and making modeling decisions based on data realities (imbalance) and downstream goals (precision vs recall).
      </p>
    </section>

    <footer>
      <p>© 2025 Andrew Cai</p>
    </footer>

  </div>
</body>
</html>
