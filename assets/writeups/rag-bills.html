<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>RAG for U.S. Congressional Bills | Andrew Cai</title>
  <meta name="description" content="Retrieval-Augmented Generation system for summarizing U.S. Congressional bills with citations." />

  <style>
    :root{
      --bg:#f7f7fb;
      --card:#ffffff;
      --ink:#1f2a44;
      --muted:#58627a;
      --brand:#2563eb;
      --ring: rgba(37,99,235,.25);
      --border:#e9e9f3;
      --shadow: 0 8px 24px rgba(31,42,68,.06);
    }
    *{ box-sizing:border-box; }
    body{
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
      background:var(--bg);
      color:var(--ink);
      margin:0;
      line-height:1.6;
    }
    .wrap{ max-width: 900px; margin:0 auto; padding:24px; }

    header{
      padding: 18px 0 8px;
    }
    header a{
      color:var(--brand);
      text-decoration:none;
      font-weight:700;
    }
    header a:hover{ text-decoration:underline; }

    h1{
      margin: 10px 0 6px;
      font-size: 1.9rem;
      letter-spacing:-.2px;
    }
    h2{
      margin-top: 26px;
      font-size: 1.25rem;
    }
    h3{
      margin-top: 18px;
      font-size: 1.05rem;
    }
    p{ margin: 10px 0; }
    ul{ margin: 8px 0 8px 18px; }
    li{ margin: 6px 0; }

    .meta{
      color:var(--muted);
      font-size:.95rem;
    }

    section{
      background:var(--card);
      border-radius:14px;
      box-shadow: var(--shadow);
      padding:20px;
      margin: 16px 0;
      border: 1px solid var(--border);
    }

    .hero img{
      width:100%;
      border-radius:12px;
      margin-top: 10px;
      background:#eaeaf3;
    }

    .pillrow{
      display:flex;
      flex-wrap:wrap;
      gap:8px;
      margin-top: 10px;
    }
    .pill{
      font-size: .88rem;
      background:#f3f6ff;
      border:1px solid #e1e6ff;
      padding:4px 10px;
      border-radius: 999px;
      white-space: nowrap;
    }

    .btn{
      display:inline-block;
      padding:8px 12px;
      border-radius:10px;
      border:1px solid #d6daf1;
      text-decoration:none;
      color:var(--brand);
      font-weight:700;
      background:#f8faff;
      margin-right: 8px;
      margin-top: 6px;
    }
    .btn:hover{
      box-shadow:0 0 0 4px var(--ring);
    }

    footer{
      text-align:center;
      color:var(--muted);
      padding:24px 0 6px;
      font-size: .9rem;
    }
  </style>
</head>

<body>
  <div class="wrap">

    <!-- Back navigation -->
    <header>
      <a href="../../index.html">← Back to Portfolio</a>
    </header>

    <!-- Title / Overview -->
    <section class="hero">
      <h1>Retrieval-Augmented Generation for U.S. Congressional Bills</h1>
      <p class="meta">
        RAG · FAISS · Semantic Search · LLM Evaluation · Streamlit · GCP
      </p>

      <!-- Optional hero image -->
      <img src="../img/rag-bills.png" alt="RAG system Streamlit interface preview" />

      <div class="pillrow">
        <span class="pill">Python</span>
        <span class="pill">FAISS</span>
        <span class="pill">all-MiniLM-L6-v2</span>
        <span class="pill">LLMs</span>
        <span class="pill">Streamlit</span>
        <span class="pill">GCP</span>
        <span class="pill">NLP</span>
      </div>

      <p>
        This project implements a Retrieval-Augmented Generation (RAG) system that answers
        legislation-related questions by retrieving and summarizing U.S. Congressional bill text
        with explicit citations.
      </p>

      <p>
        The goal is to provide transparent, verifiable, and low-hallucination responses that help
        users understand how proposed or enacted legislation may affect them.
      </p>

      <p>
        <a class="btn" href="https://github.com/YOUR_USERNAME/YOUR_RAG_REPO" target="_blank" rel="noopener">GitHub Repo</a>
        <a class="btn" href="https://YOUR_LIVE_DEMO_LINK" target="_blank" rel="noopener">Live Demo</a>
      </p>
    </section>

    <!-- Problem -->
    <section>
      <h2>Problem Statement</h2>
      <p>
        U.S. Congressional bills are lengthy, complex, and difficult for the public to interpret.
        While large language models can generate summaries, they often hallucinate facts or fail to
        reference the source material.
      </p>
      <p>
        The challenge is to build a system that provides concise, accurate answers grounded directly
        in legislative text, while maintaining reasonable response times and transparency.
      </p>
    </section>

    <!-- Approach -->
    <section>
      <h2>Approach</h2>
      <p>
        We designed a modular RAG pipeline that separates document retrieval from text generation.
        Bill text is chunked, embedded, indexed, and retrieved prior to any LLM invocation.
      </p>

      <ul>
        <li>Chunked Congressional bill text and generated embeddings using all-MiniLM-L6-v2</li>
        <li>Indexed embeddings using FAISS for efficient semantic search</li>
        <li>Retrieved top-k relevant chunks per query</li>
        <li>Generated summaries using free LLMs via OpenRouter</li>
        <li>Returned answers with citations linked to specific bills</li>
      </ul>
    </section>

    <!-- System Architecture -->
    <section>
      <h2>System Architecture</h2>
      <p>
        The system follows a retrieve-then-generate workflow. Retrieval quality is prioritized to
        minimize hallucination and ensure that generated responses remain grounded in factual text.
      </p>

      <ul>
        <li>Embedding model: <strong>all-MiniLM-L6-v2</strong></li>
        <li>Vector index: <strong>FAISS</strong></li>
        <li>LLMs evaluated: DeepSeek (lite), Gemini (lite), others via OpenRouter</li>
        <li>Frontend: Streamlit</li>
        <li>Deployment: Google Cloud Platform</li>
      </ul>
    </section>

    <!-- Evaluation -->
    <section>
      <h2>Evaluation & Findings</h2>
      <ul>
        <li>Embedding-based retrieval significantly reduced hallucinated responses</li>
        <li>Smaller, free LLMs performed adequately when retrieval quality was high</li>
        <li>Citation inclusion improved user trust and answer interpretability</li>
        <li>Latency was dominated by retrieval + LLM inference tradeoffs</li>
      </ul>
    </section>

    <!-- Challenges -->
    <section>
      <h2>Challenges & Limitations</h2>
      <ul>
        <li>Long legislative documents required careful chunking strategies</li>
        <li>Some queries spanned multiple bills, complicating citation aggregation</li>
        <li>Free LLMs varied in consistency and reasoning depth</li>
      </ul>
    </section>

    <!-- Extensions -->
    <section>
      <h2>Extensions & Future Work</h2>
      <ul>
        <li>Hybrid or multi-stage retrieval strategies</li>
        <li>Improved confidence scoring and answer reliability metrics</li>
        <li>Bill comparison and timeline-aware summarization</li>
        <li>Expanded domain coverage (state legislation, regulations)</li>
      </ul>
    </section>

    <!-- Takeaways -->
    <section>
      <h2>Key Takeaways</h2>
      <p>
        This project strengthened my understanding of modern NLP system design, particularly the
        importance of retrieval quality in controlling hallucinations. It also demonstrated how
        scalable indexing, lightweight embeddings, and modular pipelines can be combined to build
        transparent, production-oriented AI systems.
      </p>
    </section>

    <footer>
      <p>© 2025 Andrew Cai</p>
    </footer>

  </div>
</body>
</html>
